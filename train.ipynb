{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 02:10:06.877139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/max/miniconda3/envs/snake/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 02:10:07.553206: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-31 02:10:07.553659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-31 02:10:07.612246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:07.612453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.83GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-31 02:10:07.612468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 02:10:07.613404: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-31 02:10:07.613431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-31 02:10:07.614424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-31 02:10:07.614593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-31 02:10:07.615597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-31 02:10:07.616150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-31 02:10:07.618413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-31 02:10:07.618513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:07.618760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:07.618930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from game import Game\n",
    "import logging\n",
    "from board import Direction\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\n",
    "print(f\"GPU {'available' if tf.config.list_physical_devices('GPU') else 'not available'}\")\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def board_to_tensor(input_data):\n",
    "    return tf.expand_dims(\n",
    "        tf.expand_dims(\n",
    "            tf.convert_to_tensor(\n",
    "                input_data.repr(\"int\") / 4\n",
    "            ),\n",
    "            axis=-1\n",
    "        ),\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "def to_key(digit):\n",
    "    return Direction(digit)\n",
    "\n",
    "\n",
    "class EpochDots(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Makes 'model.fit' print dots at each epoch and print the\n",
    "    current epoch number in real time\n",
    "    Eg.\\n\n",
    "    10   .......... \\n\n",
    "    14   ....\n",
    "    NOTE: Make sure to set verbose == 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dots_per_line=10, epochs_per_dot=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dots: dots per line\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dots_per_line = dots_per_line\n",
    "        self.epochs_per_dot = epochs_per_dot\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        lr = self.model.optimizer.lr.numpy()\n",
    "        padding = round(math.log(self.params['epochs'], 10)) + 1\n",
    "        epoch = epoch + 1  # epochs start counting at 0 for computer, this adds 1 for human\n",
    "        if epoch % self.epochs_per_dot == 0:\n",
    "            if epoch % (self.dots_per_line * self.epochs_per_dot) == 0:  # Every 100 epochs\n",
    "                print(f\"\\r{epoch:{padding}} \" + \".\" * self.dots_per_line, logs, f\"lr: {lr}\", end=\"\\n\")\n",
    "            else:\n",
    "                dots = int(epoch / self.epochs_per_dot) % self.dots_per_line\n",
    "                print(f\"\\r{epoch:{padding}} \"+ f\"{'.'*dots:{self.dots_per_line}}\", logs, f\"lr: {lr}\",  end=\"\")\n",
    "\n",
    "class EarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') >= 0.95:\n",
    "            print(\"\\nReached >= 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 18, 18, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2363392   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 35,961,220\n",
      "Trainable params: 35,961,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 02:10:07.648802: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-31 02:10:07.648994: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-31 02:10:07.649109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:07.649308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.83GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-31 02:10:07.649329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 02:10:07.649343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-31 02:10:07.649351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-31 02:10:07.649358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-31 02:10:07.649365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-31 02:10:07.649372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-31 02:10:07.649379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-31 02:10:07.649386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-31 02:10:07.649426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:07.649650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:07.649960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-31 02:10:07.649983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 02:10:08.019630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-31 02:10:08.019651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-31 02:10:08.019655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-31 02:10:08.019794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:08.020042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:08.020249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 02:10:08.020433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4859 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(filename=\"logs.txt\",\n",
    "                    level=logging.CRITICAL,\n",
    "                    filemode=\"w\",\n",
    "                    format=\"%(levelname) -9s %(module)s:%(lineno)s %(funcName) -10s %(message)s\")\n",
    "\n",
    "# Game parameters\n",
    "HEIGHT = 20\n",
    "WIDTH = 20\n",
    "\n",
    "\n",
    "\n",
    "# TODO: add convolutions\n",
    "# TODO: get rid of magic number 4\n",
    "model = Sequential([\n",
    "    # Flatten(input_shape=(HEIGHT, WIDTH)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(HEIGHT, WIDTH, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "\n",
    "    layers.Dense(4)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 0\n",
      "Randomness: 1.0\n",
      "\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25hMax reward: [-100 -100 -100]\n",
      "Min reward: [-100 -100 -100]\n",
      "Training on 9 steps\n",
      "   10 .                                                                                {'loss': 0.38676849007606506, 'accuracy': 0.8888888955116272} lr: 0.0010000000474974513\n",
      "Reached >= 95% accuracy so cancelling training!\n",
      "Generation: 1\n",
      "Randomness: 0.513417119032592\n",
      "\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25hMax reward: [-100  -80  -80]\n",
      "Min reward: [-100 -100 -100]\n",
      "Training on 13 steps\n",
      "   20 ..                                                                               {'loss': 0.22027502954006195, 'accuracy': 0.8461538553237915} lr: 0.0010000000474974513\n",
      "Reached >= 95% accuracy so cancelling training!\n",
      "Generation: 2\n",
      "Randomness: 0.26359713811572677\n",
      "\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25h\u001B[?25hMax reward: [-100 -100 -100]\n",
      "Min reward: [-100 -100 -100]\n",
      "Training on 13 steps\n",
      "   20 ..                                                                               {'loss': 0.14585629105567932, 'accuracy': 0.9230769276618958} lr: 0.0010000000474974513\n",
      "Reached >= 95% accuracy so cancelling training!\n"
     ]
    }
   ],
   "source": [
    "GENERATIONS = 3\n",
    "GAMES = 100  # Number of games to play before updating the model\n",
    "KEEP = 3  # games to keep for training\n",
    "MAX_STEPS = 20 # Maximum number of steps per game\n",
    "\n",
    "max_reward = -100\n",
    "for generation in range(GENERATIONS):\n",
    "    randomness = 1 * math.exp(-2*generation/GENERATIONS)\n",
    "\n",
    "    observations = np.full(\n",
    "        (GAMES, MAX_STEPS, HEIGHT, WIDTH, 1),\n",
    "        -1,\n",
    "        np.float32\n",
    "    )\n",
    "    predictions = np.full(\n",
    "        (GAMES, MAX_STEPS, 1),\n",
    "        -1,\n",
    "        dtype=np.int8\n",
    "    )\n",
    "\n",
    "    # HACK: give a better default value\n",
    "    rewards = np.full(GAMES, -10000, dtype=np.int32)\n",
    "    print(f\"Generation: {generation}\")\n",
    "    print(f\"Randomness: {randomness}\")\n",
    "\n",
    "    # Loop over games\n",
    "    for game_idx in range(GAMES):\n",
    "        # Initialize game\n",
    "        game = Game(HEIGHT, WIDTH)\n",
    "\n",
    "        # Initial step information\n",
    "        observation = board_to_tensor(game.board)\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        total_reward = 0\n",
    "\n",
    "        # Play game\n",
    "        step = 0\n",
    "        while step < MAX_STEPS and not (terminated or truncated):\n",
    "            model_prediction = tf.argmax(\n",
    "                tf.math.softmax(model(observation)),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            random_prediction = random.randint(0, 3)\n",
    "\n",
    "            prediction = random_prediction if random.random() < randomness else model_prediction\n",
    "\n",
    "            observations[game_idx, step] = observation\n",
    "            predictions[game_idx, step] = prediction\n",
    "\n",
    "            key = to_key(prediction)\n",
    "            observation, reward, terminated, truncated, info = game.step(key)\n",
    "            observation = board_to_tensor(observation)\n",
    "\n",
    "            total_reward += reward\n",
    "            step += 1\n",
    "\n",
    "        rewards[game_idx] = total_reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    max_args = np.argsort(rewards)[-KEEP:]\n",
    "    min_args = np.argsort(rewards)[:KEEP]\n",
    "    print(f\"Max reward: {rewards[max_args]}\")\n",
    "    print(f\"Min reward: {rewards[min_args]}\")\n",
    "\n",
    "    # if rewards[max_args][-1] <= max_reward:\n",
    "    #     print(\"Skipping\")\n",
    "    #     continue\n",
    "    # else:\n",
    "    #     max_reward = rewards[max_args][-1]\n",
    "\n",
    "\n",
    "\n",
    "    # Only use the best games for training\n",
    "    observations = observations[max_args]\n",
    "    predictions = predictions[max_args]\n",
    "\n",
    "    # Concatenate games\n",
    "    observations = observations.reshape(-1, HEIGHT, WIDTH, 1)\n",
    "    predictions = predictions.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Remove any steps that were not played\n",
    "    good_indices = (predictions > 0).reshape(-1)\n",
    "    observations = observations[good_indices]\n",
    "    predictions = predictions[good_indices]\n",
    "\n",
    "\n",
    "    GEN_DIR = \"generations\"\n",
    "    os.makedirs(GEN_DIR, exist_ok=True)\n",
    "    plays = os.path.join(GEN_DIR, f\"gen_{generation}\")\n",
    "    np.savez(plays, observations)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Training on {len(observations)} steps\")\n",
    "\n",
    "    model.fit(\n",
    "        observations,\n",
    "        predictions,\n",
    "        batch_size=1024,\n",
    "        epochs=10000,\n",
    "        callbacks=[\n",
    "            EpochDots(dots_per_line=80, epochs_per_dot=10),\n",
    "            EarlyStopping()\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?25h"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Game' object has no attribute 'render'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m key \u001B[38;5;241m=\u001B[39m to_key(model_prediction)\n\u001B[1;32m     13\u001B[0m observation, reward, terminated, truncated, info \u001B[38;5;241m=\u001B[39m game\u001B[38;5;241m.\u001B[39mstep(key)\n\u001B[0;32m---> 14\u001B[0m \u001B[43mgame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m()\n\u001B[1;32m     15\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m     16\u001B[0m step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Game' object has no attribute 'render'"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "game = Game(HEIGHT, WIDTH)\n",
    "observation = game.board.tensor()\n",
    "terminated = False\n",
    "truncated = False\n",
    "step = 0\n",
    "while step < MAX_STEPS and not (terminated or truncated):\n",
    "    model_prediction = tf.argmax(\n",
    "        tf.math.softmax(model(observation)),\n",
    "        axis=1\n",
    "    )\n",
    "    key = to_key(model_prediction)\n",
    "    observation, reward, terminated, truncated, info = game.step(key)\n",
    "    game.render()\n",
    "    time.sleep(0.1)\n",
    "    step += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('snake')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "cce852e02f257335b50705bb242ee663c863e66a80b0390fe7c492a2ca73d186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}